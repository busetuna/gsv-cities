# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m6uhmInXCiyYXlZR6LyWStnxmUOPx4cY
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array

def classify_and_show_image(img_path, model, target_size=(224, 224)):
    """
    Verilen bir görüntünün sınıflandırılmasını sağlar ve ekrana görüntüyü
    şehir ismi ile birlikte yazdırır.

    Args:
    img_path (str): Sınıflandırılacak görüntünün dosya yolu.
    model (tf.keras.Model): Eğitilmiş model.
    target_size (tuple): Modelin beklediği giriş görüntüsü boyutu.
    """
    # Görüntüyü yükle ve yeniden boyutlandır
    img = load_img(img_path, target_size=target_size)
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0

    # Tahmin yap
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction, axis=1)

    # Sınıf etiketlerini al
    class_labels = list(train_generator.class_indices.keys())
    predicted_city = class_labels[predicted_class[0]]

    # Görüntüyü ekrana getir ve şehir ismini göster
    plt.imshow(load_img(img_path))
    plt.title(f"Predicted City: {predicted_city}")
    plt.axis('off')  # Eksenleri gizle
    plt.show()

# Örnek kullanımı
img_path = '/content/drive/My Drive/Colab Notebooks/Proje denemesi/train/train Medellin/Medellin_0000004_2019_03_127_6.231040383821977_-75.60448618489751_x5aHmuMi7K521eix2MG0ZA.jpg'
classify_and_show_image(img_path, model)

!pip install tensorflow

import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam

train_dir = '/content/drive/My Drive/Colab Notebooks/Proje denemesi/train'
test_dir = '/content/drive/My Drive/Colab Notebooks/Proje denemesi/test'

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam

# Veri artırma ve yeniden ölçeklendirme
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/My Drive/Colab Notebooks/Proje denemesi/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/Colab Notebooks/Proje denemesi/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# ResNet50 Modeli
resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# ResNet50'nin katmanlarını dondurma
for layer in resnet_base.layers:
    layer.trainable = False

# Modeli oluşturma
model = Sequential([
    resnet_base,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Modeli derleme
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Modeli eğitme
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=1,
    validation_data=test_generator,
    validation_steps=len(test_generator)
)

# Modeli değerlendirme
test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))
print(f"Test Accuracy: {test_acc}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam

# Veri artırma ve yeniden ölçeklendirme
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/My Drive/Colab Notebooks/Proje denemesi/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/Colab Notebooks/Proje denemesi/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# ResNet50 Modeli
resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# ResNet50'nin katmanlarını dondurma
for layer in resnet_base.layers:
    layer.trainable = False

# Modeli oluşturma
model = Sequential([
    resnet_base,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Modeli derleme
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Modeli eğitme
history = model.fit(
    train_generator,
    steps_per_epoch=100,  # Her epoch 100 adımda tamamlanacak
    epochs=5,
    validation_data=test_generator,
    validation_steps=50  # Validation da aynı şekilde 50 adımda tamamlanacak
)

# Modeli değerlendirme
test_loss, test_acc = model.evaluate(test_generator, steps=50)  # Değerlendirme de 50 adımda yapılacak
print(f"Test Accuracy: {test_acc}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
import numpy as np

# Veri artırma ve yeniden ölçeklendirme
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/My Drive/Colab Notebooks/Proje denemesi/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/Colab Notebooks/Proje denemesi/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# VGG16 Modeli
vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# VGG16'nin katmanlarını dondurma
for layer in vgg_base.layers:
    layer.trainable = False

# Modeli oluşturma
model = Sequential([
    vgg_base,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Modeli derleme
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Modeli eğitme
history = model.fit(
    train_generator,
    steps_per_epoch=100,  # Her epoch 100 adımda tamamlanacak
    epochs=1,
    validation_data=test_generator,
    validation_steps=50  # Validation da aynı şekilde 50 adımda tamamlanacak
)

# Modeli değerlendirme
test_loss, test_acc = model.evaluate(test_generator, steps=50)  # Değerlendirme de 50 adımda yapılacak
print(f"Test Accuracy: {test_acc}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Veri artırma ve yeniden ölçeklendirme
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

# Model oluşturma
model = Sequential([
    Conv2D(128, (5, 5), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(3, 3),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Modeli derleme
model.compile(optimizer=Adam(lr=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Modeli eğitme
history = model.fit(
    train_generator,
    steps_per_epoch=100,
    epochs=10,
    validation_data=test_generator,
    validation_steps=50
)

# Modeli değerlendirme
test_loss, test_acc = model.evaluate(test_generator, steps=50)
print(f"Test Accuracy: {test_acc}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam

# Veri artırma ve yeniden ölçeklendirme
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# ResNet50 Modeli
resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# ResNet50'nin katmanlarını dondurma
for layer in resnet_base.layers:
    layer.trainable = False

# Modeli oluşturma
model = Sequential([
    resnet_base,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Modeli derleme
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Modeli eğitme
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=10,
    validation_data=test_generator,
    validation_steps=len(test_generator)
)

# Modeli değerlendirme
test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))
print(f"Test Accuracy: {test_acc}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Data augmentation and rescaling
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

# Model creation
model = Sequential([
    Conv2D(64, (5, 5), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(3, 3),
    Conv2D(128, (5, 5), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(100, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Model compilation
model.compile(optimizer=Adam(lr=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Model training
history = model.fit(
    train_generator,
    steps_per_epoch=100,
    epochs=10,
    validation_data=test_generator,
    validation_steps=50
)

# Model evaluation
test_loss, test_acc = model.evaluate(test_generator, steps=50)
print(f"Test Accuracy: {test_acc}")

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array

def classify_image(img_path, model, target_size=(224, 224)):
    """
    Verilen bir görüntünün sınıflandırılmasını sağlar.

    Args:
    img_path (str): Sınıflandırılacak görüntünün dosya yolu.
    model (tf.keras.Model): Eğitilmiş model.
    target_size (tuple): Modelin beklediği giriş görüntüsü boyutu.

    Returns:
    prediction (np.array): Sınıflandırma sonuçları.
    """
    # Görüntüyü yükle ve yeniden boyutlandır
    img = load_img(img_path, target_size=target_size)
    # Görüntüyü numpy array'e çevir
    img_array = img_to_array(img)
    # Modelin beklediği şekle sok
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    # Tahmin yap
    prediction = model.predict(img_array)
    return prediction

# Örnek kullanımı
img_path = '/content/drive/My Drive/Colab Notebooks/Proje denemesi/train/train OSL/OSL_0000024_2018_12_300_59.89805420199208_10.75612223626256_PLPfym0h5eeub7YAzpEj9A.jpg'
prediction = classify_image(img_path, model)
predicted_class = np.argmax(prediction, axis=1)
class_labels = list(train_generator.class_indices.keys())
print(f"Predicted country: {class_labels[predicted_class[0]]}")